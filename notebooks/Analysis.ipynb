{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analysis of Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "- Justification for analysis\n",
    "- Growth functions\n",
    "- Counting machine instructions\n",
    "- Landau symbols\n",
    "- Big-$\\Theta$ as an equivalence relation\n",
    "- Little-$o$ as a weak ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Background\n",
    "\n",
    "- Suppose we have two algorithms, how can we tell which is better?\n",
    "\n",
    "- We could implement both algorithms, run them both\n",
    "    - Expensive and error prone\n",
    "\n",
    "- Preferably, we should analyze them mathematically\n",
    "    - Algorithm analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Asymptotic Analysis\n",
    "\n",
    "- In general, we will always analyze algorithms with respect to one or more variables\n",
    "\n",
    "- We will begin with one variable:\n",
    "    - The number of items $n$ currently stored in an array or other data structure\n",
    "    - The number of items expected to be stored in an array or other data structure\n",
    "    - The dimensions of an $n \\times n$ matrix\n",
    "    \n",
    "- Examples with multiple variables:\n",
    "    - Dealing with $n$ objects stored in $m$ memory locations\n",
    "    - Multiplying a $k \\times n$ and an $m \\times n$ matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Maximum Value\n",
    "\n",
    "- For example, the time taken to find the largest object in an array of $n$ random integers will take $n$ operations\n",
    "\n",
    "```cpp\n",
    "int find_max( int *array, int n ) {\n",
    "    int max = array[0];\n",
    "    for ( int i = 1; i < n; ++i ) {\n",
    "        if ( array[i] > max ) {\n",
    "            max = array[i];\n",
    "        }\n",
    "    }\n",
    "    return max;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear and binary search\n",
    "\n",
    "- There are other algorithms which are significantly faster as the problem size increases\n",
    "- This plot shows maximum and average number of comparisons to find an entry in a sorted array of size $n$\n",
    "    - Linear search (blue)\n",
    "    - Binary search (read)\n",
    "![](../img/search-comp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Asymptotic Analysis\n",
    "\n",
    "- Given an algorithm:\n",
    "    - We need to be able to describe these values mathematically\n",
    "    - We need a systematic means of using the description of the algorithm together with the properties of an associated data structure\n",
    "    - We need to do this in a machine-independent way\n",
    "\n",
    "- For this, we need Landau symbols and the associated asymptotic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quadratic Growth\n",
    "\n",
    "- Consider the two functions <span style=\"color:red\"> $f(n) = n^2$ </span> and <span style=\"color:blue\"> $g(n) = n^2 - 3n + 2$ </span>\n",
    "- Around $n = 0$, they look very different\n",
    "![](../img/qgrowth1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Yet on the range $n = [0, 1000]$, they are (relatively) indistinguishable:\n",
    "![](../img/qgrowth2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The **absolute difference** is large, for example,\n",
    "\n",
    "    - $f(1000) = 1 000 000$\n",
    "\t- $g(1000) =   997 002$\n",
    "    \n",
    "- but the **relative difference** is very small\n",
    "\n",
    "$$\\left| \\frac{f(1000)-g(1000)}{f(1000)} \\right| = 0.002998 < 0.3\\%$$\n",
    "\n",
    "- and this difference goes to zero as $n  \\to \\infty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Polynomial Growth\n",
    "\n",
    "- To demonstrate with another example,\n",
    "  - <span style=\"color:red\"> $f(n) = n^6$ </span>\n",
    "  - <span style=\"color:blue\"> $g(n) = n^6 - 23n^5 + 193n^4 -729n^3 + 1206n^2 - 648n$ </span>\n",
    "\n",
    "- Around $n = 0$, they look very different\n",
    "![](../img/pgrowth1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Still, around $n = 1000$, the relative difference is less than 3%\n",
    "![](../img/pgrowth2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The justification for both pairs of polynomials being similar is that, in both cases, they each had the same leading term:\n",
    "\t- $n^2$ in the first case, $n^6$ in the second\n",
    "\n",
    "- Suppose however, that the coefficients of the leading terms were different\n",
    "    - In this case, both functions would exhibit the same rate of growth, however, one would always be proportionally larger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparing Growth Rates\n",
    "\n",
    "| constant | logarithm | linear | n-log-n | quadratic | cubic | exponential |\n",
    "|:--------:|:---------:|:------:|:-------:|:---------:|:-----:|:-----------:|\n",
    "| 1        | $\\log n$  | $n$    |$n$ $\\log n$| $n^2$     | $n^3$ | $a^n$       |\n",
    "\n",
    "![](../img/growth.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Counting Instructions\n",
    "\n",
    "- Suppose we had two algorithms which sorted a list of size $n$ and the run time (in ms) is given by\n",
    "    - Bubble sort \n",
    "        - <span style=\"color:red\"> $b_{worst}(n)= 4.7n^2 - 0.5^n + 5$ </span>\n",
    "        - <span style=\"color:red\"> $b_{best}(n) = 3.8n^2 + 0.5^n + 5$ </span>\n",
    "    - Selection sort\n",
    "        - <span style=\"color:blue\"> $s(n)\t= 4n^2 + 14^n + 12$\t</span>\n",
    "\n",
    "- The smaller the value, the fewer instructions are run\n",
    "    - For $n \\leq 21$, <span style=\"color:red\"> $b_{worst}(n)$ </span> $<$ <span style=\"color:blue\"> $s(n)$ </span>\n",
    "    - For $n \\geq 22$, <span style=\"color:red\"> $b_{worst}(n)$  </span> $>$ <span style=\"color:blue\"> $s(n)$ </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- With small values of $n$, the algorithm described by  <span style=\"color:blue\"> $s(n)$ </span> requires more instructions than even the worst-case for bubble sort\n",
    "![](../img/perf1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- \tNear $n = 1000$, <span style=\"color:red\"> $b_{worst}(n)$ </span> ≈ 1.175 <span style=\"color:blue\"> $s(n)$ </span>, and <span style=\"color:red\"> $b_{best}(n)$ </span>  ≈  0.95 <span style=\"color:blue\"> $s(n)$ </span>\n",
    "\n",
    "![](../img/perf2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Is this a serious difference between these two algorithms?\n",
    "    - Because we can count the number instructions, we can also estimate how much time is required to run one of these algorithms on a computer\n",
    "    \n",
    "- Suppose we have a 1 GHz computer\n",
    "    - The time (s) required to sort a list of up to $n = 10 000$ objects is under 0.5s\n",
    "\t- To sort a list with one million elements, it will take about 1 hour    \n",
    "    ![](../img/perf3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- What if we run selection sort on a faster computer?\n",
    "    - For large values of $n$, selection sort on a faster computer will always be faster than bubble sort.\n",
    "    ![](../img/perf4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Why? Justification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Counting Instructions (cont.)\n",
    "\n",
    "- If  <span style=\"color:red\"> $f(n)$ </span> $= a_kn^k + \\cdots$ and  <span style=\"color:blue\"> $g(n)$  </span> $= b_kn^k + \\cdots$, for large enough $n$, it will always be true that\n",
    "$$f(n) < Mg(n)$$\n",
    "    - where we choose $M = a_k/b_k + 1$\n",
    "\n",
    "- In this case, we only need a computer which is $M$ times faster (or slower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Weak Ordering\n",
    "\n",
    "- Consider the following definitions:\n",
    "\n",
    "    - We will consider two functions to be equivalent, $f \\sim g$, if\n",
    "$$\\lim_{n \\to \\infty} \\frac{f(n)}{g(n)} = c, \\text{ where } 0 < c < \\infty $$\n",
    "\t\t\t\t\n",
    "    - We will state that $f < g$ if\n",
    "$$\\lim_{n \\to \\infty} \\frac{f(n)}{g(n)} = 0 $$\n",
    "\n",
    "\n",
    "- For functions we are interested in, these define a **weak ordering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Let $f(n)$ and $g(n)$ describe either the run-time of two algorithms\n",
    "    - If $f(n) \\sim g(n)$, then it is always possible to improve the performance of one function over the other by purchasing a faster computer\n",
    "    - If $f(n) < g(n)$, then you can **never** purchase a computer fast enough so that the second function always runs in less time than the first\n",
    "\n",
    "- Note that for small values of $n$, it may be reasonable to use an algorithm that is asymptotically more expensive, but we will consider these on a one-by-one basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [Big-O Notation](https://en.wikipedia.org/wiki/Big_O_notation)\n",
    "\n",
    "- A function $f(n) = O(g(n))$ if there exists $n_0$ and $c$ such that\n",
    "$$f(n) \\leq c g(n)\t\\text{,  whenever  } n \\geq n_0$$\n",
    "- The function $f(n)$ has a rate of growth **no greater than** that of $g(n)$ up to a constant factor and in the **asymptotic** sense as $n$ grows toward infinity.    \n",
    "\n",
    "![](../img/big-o.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Assumptions    \n",
    "\n",
    "- Our functions will describe the time or memory required to solve a problem of size $n$\n",
    "- We conclude we are restricting ourselves to certain functions:\n",
    "    - They are defined for $n \\geq 0$\n",
    "    - They are strictly positive for all $n$\n",
    "        - In fact, $f(n) > c$ for some value $c > 0$\n",
    "        - That is, any problem requires at least one instruction and byte\n",
    "    - They are *increasing* (monotonic increasing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "- If $f(n)$ is a polynomial of degree $d$,\n",
    "$$f(n) = a_dn^d + \\cdots + a_1n +a_0$$\n",
    "and $a_d > 0$, then $f(n)$ is $O(n^d)$\n",
    "\n",
    "- Justification\n",
    "    - for $n \\geq 1$, we have $n^d \\geq n^{d-1} \\geq \\cdots \\geq n \\geq 1$; hence\n",
    "    $$a_dn^d + \\cdots + a_1n +a_0 \\leq (a_d + \\cdots + a_1 +a_0)n^d$$\n",
    "    - therefor $f(n)$ is $O(n^d)$ by defining $c = a_d + \\cdots + a_1 +a_0$ and $n_0 = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Landau Symbols: Big Theta\n",
    "\n",
    "- A function $f(n) = \\Theta(g(n))$ if there exists $n_0$, $c_1$ and $c_2$ such that\n",
    "$$c_1 g(n)< f(n) < c_2 g(n)\t\\text{,  whenever  } n \\geq n_0$$\n",
    "- The function $f(n)$ has a *rate of growth* ***equal*** to that of $g(n)$.\n",
    "- Limit Definition\n",
    "    $$\\lim_{n \\to \\infty}\\frac{f(n)}{g(n)} = c \\text{, where } 0 < c < \\infty$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Knuth: \"For all the applications I have seen so far in computer science, a stronger requirement ... is much more appropriate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Limits of polynomial functions\n",
    "\n",
    "- If $f(n)$ is a polynomial of degree $d$,\n",
    "\n",
    "$$f(n) = a_d n^d + \\cdots + a_1 n +a_0$$\n",
    "\n",
    "- Then\n",
    "$$\\lim_{n\\to \\pm \\infty} f(n) = \\lim_{n\\to \\pm \\infty} a_d n^d = \\pm \\infty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\lim_{n\\to \\infty} f(n) = \\lim_{n\\to \\infty} (a_d n^d + \\cdots + a_1 n +a_0)$$\n",
    "$$ = \\lim_{n\\to \\infty} a_d n^d \\left(1 + \\frac{a_{d-1}n^{d-1}}{a_dn^d} \\cdots + \\frac{a_1 n}{a_d n^d} + \\frac{a_0}{a_d n^d} \\right)$$\n",
    "$$ = \\lim_{n\\to \\infty} a_d n^d \\lim_{n\\to \\infty}\\left(1 + \\frac{a_{d-1}}{a_d n} \\cdots + \\frac{a_1}{a_d n^{d-1}} + \\frac{a_0}{a_d n^d} \\right) $$\n",
    "$$ = \\lim_{n\\to \\infty} a_d n^d \\cdot 1$$\n",
    "$$ = \\lim_{n\\to \\infty} a_d n^d = \\infty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "- If $f(n) = 42n^2 + 32$ then $f(n)$ is $\\Theta(n^2)$\n",
    "\n",
    "- Justification\n",
    "$$\\lim_{n \\to \\infty}\\frac{f(n)}{g(n)} = \\lim_{n \\to \\infty}\\frac{42n^2 + 32}{n^2}$$\n",
    "$$ = \\lim_{n \\to \\infty} \\left(42 + \\frac{32}{n^2} \\right) = \\lim_{n \\to \\infty} (42 + 0) = 42$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "hide_input": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table.custom td.custom {\n",
       "    border: 1px solid black;\n",
       "}\n",
       "th.custom {\n",
       "    border: 1px solid black;\n",
       "    text-align: center;\n",
       "}\n",
       "td.custom {\n",
       "    border: 1px solid black;\n",
       "    text-align: center;    \n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table.custom td.custom {\n",
    "    border: 1px solid black;\n",
    "}\n",
    "th.custom {\n",
    "    border: 1px solid black;\n",
    "    text-align: center;\n",
    "}\n",
    "td.custom {\n",
    "    border: 1px solid black;\n",
    "    text-align: center;    \n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Landau Notation\n",
    "\n",
    "We will at times use five possible descriptions\n",
    "\n",
    "<table class=\"custom\">\n",
    "    <tr>\n",
    "        <th class=\"custom\">Symbol</th>\n",
    "        <th class=\"custom\">Limit</th>\n",
    "        <th class=\"custom\">Description</th>\n",
    "        <th class=\"custom\">Analogous Relational Operator</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td class=\"custom\" style=\"width:25%\">$f(n) = \\omega(g(n))$</td>\n",
    "        <td class=\"custom\" style=\"width:25%\">$$\\lim_{n \\to \\infty}\\frac{f(n)}{g(n)}=\\infty$$</td>\n",
    "        <td class=\"custom\" style=\"width:35%; text-align:center\">$f$ grows significantly faster than $g$</td>\n",
    "        <td class=\"custom\" style=\"width:15%; text-align:center\">$>$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td class=\"custom\" style=\"width:25%\">$f(n) = \\Omega(g(n))$</td>\n",
    "        <td class=\"custom\" style=\"width:25%\">$$ 0 < \\lim_{n \\to \\infty}\\frac{f(n)}{g(n)} $$</td>\n",
    "        <td class=\"custom\" style=\"width:35%; text-align:center\">$f$ grows at the same rate as or faster than $g$</td>\n",
    "        <td class=\"custom\" style=\"width:15%; text-align:center\">$\\geq$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td class=\"custom\" style=\"width:25%\">$f(n) = \\Theta(g(n))$</td>\n",
    "        <td class=\"custom\" style=\"width:25%\"> $$0 < \\lim_{n \\to \\infty}\\frac{f(n)}{g(n)} < \\infty$$</td>\n",
    "        <td class=\"custom\" style=\"width:35%; text-align:center\">$f$ grows at the same rate as $g$</td>\n",
    "        <td class=\"custom\" style=\"width:15%; text-align:center\">$=$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td class=\"custom\" style=\"width:25%\">$f(n) = O(g(n))$</td>\n",
    "        <td class=\"custom\" style=\"width:25%\">$$\\lim_{n \\to \\infty}\\frac{f(n)}{g(n)}  < \\infty $$</td>\n",
    "        <td class=\"custom\" style=\"width:35%; text-align:center\">$f$ grows at the same rate as or slower than $g$</td>\n",
    "        <td class=\"custom\" style=\"width:15%; text-align:center\">$\\leq$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td class=\"custom\" style=\"width:25%\">$f(n) = o(g(n))$</td>\n",
    "        <td class=\"custom\" style=\"width:25%\">$$\\lim_{n \\to \\infty}\\frac{f(n)}{g(n)}=0$$</td>\n",
    "        <td class=\"custom\" style=\"width:35%; text-align:center\">$f$ grows significantly slower than $g$</td>\n",
    "        <td class=\"custom\" style=\"width:15%; text-align:center\">$<$</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Graphically, we can summarize these as follows:\n",
    "![](../img/landau.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Some other observations we can make are:\n",
    "$$f(n) = \\Theta(g(n)) \\Leftrightarrow g(n) = \\Theta(f(n))$$\n",
    "$$f(n) = O(g(n)) \\Leftrightarrow g(n) = \\Omega(f(n))$$\n",
    "$$f(n) = o(g(n))  \\Leftrightarrow g(n) = \\omega(f(n))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Big-$\\Theta$ as an Equivalence Relation\n",
    "\n",
    "- If we look at the first relationship, we notice that $f(n) = \\Theta(g(n))$ seems to describe an equivalence relation:\n",
    "1. $f(n) = \\Theta(g(n))$ if and only if $g(n) = \\Theta(f(n))$\n",
    "2. $f(n) = \\Theta(f(n))$\n",
    "3. If $f(n) = \\Theta(g(n))$ and $g(n) = \\Theta(h(n))$, it follows that $f(n) = \\Theta(h(n))$\n",
    "\n",
    "- Consequently, we can group all functions into equivalence classes, where all functions within one class are big-theta $\\Theta$ of each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "- For example, all of these functions are big-$\\Theta$ of each other\n",
    "$$100000 n^2 - 4n + 19$$\n",
    "$$n^2 + 1000000$$\n",
    "$$323 n^2 - 4 n ln(n) + 43 n + 10$$\n",
    "$$42n^2 + 32$$\n",
    "$$n^2 + 61 n \\log^2(n) + 7n + 14 \\log^3(n) + \\log(n)$$\n",
    "\n",
    "\n",
    "- For example\n",
    "$$42n^2 + 32 = \\Theta( 323 n^2 - 4 n \\log(n) + 43 n + 10)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logarithms and Exponentials\n",
    "\n",
    "- Recall that all logarithms are scalar multiples of each other\n",
    "    - Therefore $\\log_b(n) = \\Theta(\\ln(n))$ for any base $b$\n",
    "- Alternatively, there is no single equivalence class for exponential functions:\n",
    "    - If $1 < a < b$,\n",
    "    $$ \\lim_{n\\to\\infty} \\frac{a^n}{b^n} = \\lim_{n\\to\\infty} \\left(\\frac{a}{b}\\right)^n = 0$$ \n",
    "\n",
    "    - Therefore $a^n = o(b^n)$ \n",
    "\n",
    "- However, we will see that it is almost universally undesirable to have an exponentially growing function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We can show that, for any $p > 0$\n",
    "$$\\ln( n ) = o( n^p )$$\n",
    "\n",
    "\n",
    "- Proof: Using [l’Hôpital's rule](https://en.wikipedia.org/wiki/L%27H%C3%B4pital%27s_rule), we have\n",
    "$$\\lim_{n\\to\\infty} \\frac{\\ln(n)}{n^p} = \\lim_{n\\to\\infty} \\frac{1/n}{p n^{p-1}} = \\lim_{n\\to\\infty} \\frac{1}{p n^p} = \\frac{1}{p}\\lim_{n\\to\\infty} n^{-p} = 0$$\n",
    "\n",
    "- Conversely, $1 = o( \\ln( n ))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Other observations:\n",
    "    - If $p$ and $q$ are real positive numbers where $p < q$, it follows that\n",
    "    $$n^p = o(n^q)$$\n",
    "\n",
    "- For example, matrix-matrix multiplication is $\\Theta(n^3)$ but a refined algorithm is $\\Theta(n^{\\log_2(7)})$ where $\\log_2(7) \\approx 2.81$\n",
    "\n",
    "- Also, $n^p = o(\\ln(n)n^p)$, but $\\ln(n)n^p = o(n^q)$\n",
    "    - $n^p$ has a slower rate of growth than $\\ln(n)n^p$, but\n",
    "    - $\\ln(n)n^p$ has a slower rate of growth than $n^q$ for $p < q$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Little-$o$ as a Weak Ordering\n",
    "\n",
    "- If we restrict ourselves to functions $f(n)$ which are $\\Theta(n^p)$ and $\\Theta(\\ln(n)n^p)$, we note:\n",
    "    - It is never true that $f(n) = o(f(n))$\n",
    "    - If $f(n) \\neq \\Theta(g(n))$, it follows that either \n",
    "      $$f(n) = o(g(n)) \\text{ or } g(n) = o(f(n))$$\n",
    "    - If $f(n) = o(g(n))$ and $g(n) = o(h(n))$, it follows that $f(n) = o(h(n))$\n",
    "\n",
    "- This defines a *weak ordering*!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Graphically, we can shown this relationship by marking these against the real line\n",
    "![](../img/weak-o.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algorithms Analysis\n",
    "\n",
    "- The goal of algorithm analysis is to take a block of code and determine the **asymptotic run time** or **asymptotic memory requirements** based on various parameters\n",
    "- E.g. given an array of size $n$:\n",
    "    - Selection sort requires $\\Theta(n^2)$ time \n",
    "    - Merge sort, quick sort, and heap sort all require $\\Theta(n \\ln(n))$ time\n",
    "    - However:\n",
    "        - Merge sort requires $\\Theta(n)$ additional memory \n",
    "        - Quick sort requires $\\Theta(\\ln(n))$ additional memory\n",
    "        - Heap sort requires  $\\Theta(1)$ memory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We will use Landau notation to describe the complexity of algorithms\n",
    "    - E.g., adding a list of $n$ doubles will be said to be a $\\Theta(n)$ algorithm\n",
    "\n",
    "- An algorithm is said to have **polynomial time complexity** if its run-time may be described by $O(n^d)$ for some fixed $d \\geq 0$\n",
    "    - We will consider such algorithms to be *efficient*\n",
    "\n",
    "- Problems that have no known polynomial-time algorithms are said to be **intractable**\n",
    "    - Traveling salesman problem: find the shortest path that visits $n$ cities\n",
    "    - Best run time: $\\Theta(n^2 2^n)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivation\n",
    "\n",
    "- The asymptotic behavior of algorithms indicates the ability to **scale**\n",
    "    - Suppose we are sorting an array of size $n$\n",
    "    - Selection sort has a run time of $\\Theta(n^2)$\n",
    "        - $2n$ entries requires $(2n)^2 = 4n^2$\n",
    "            - Four times as long to sort\n",
    "        - $10n$ entries requires $(10n)^2 = 100n^2$\n",
    "            - One hundred times as long to sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The other sorting algorithms have $\\Theta(n \\ln(n))$ run times\n",
    "    - $2n$ entries require $(2n) \\ln(2n)$ = $(2n) (\\ln(n) + 1) = 2(n \\ln(n)) + 2n$\n",
    "    - $10n$ entries require $(10n) \\ln(10n) = (10n) (\\ln(n) + 1) = 10(n \\ln(n)) + 10n$\n",
    "\n",
    "- In each case, it requires $\\Theta(n)$ more time\n",
    "\n",
    "- However\n",
    "    - Merge sort will require twice and 10 times as much memory\n",
    "    - Quick sort will require one or four additional memory locations\n",
    "    - Heap sort will not require any additional memory       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we are required to store both objects and relations, both memory and time will **increase**\n",
    "    - Our goal will be to *minimize* this increase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- To properly investigate the determination of run times asymptotically, we'll discuss\n",
    "    - Machine instructions\n",
    "    - Operations\n",
    "    - Control statements\n",
    "    - Conditional statements and loops\n",
    "    - Functions\n",
    "    - Recursive functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Instructions\n",
    "\n",
    "- Given any processor, it is capable of performing only a limited number of *operations*\n",
    "- These operations are called **instructions**\n",
    "- Any instruction runs in a **fixed** amount of time (an integral number of CPU cycles)\n",
    "- Assembly language has an almost one-to-one translation to machine instructions\n",
    "    - Assembly language is a low-level programming language\n",
    "- The C programming language (C++ without objects and other abstractions) can be referred to as a mid-level programming language\n",
    "    - There is abstraction, but the language is closely tied to the standard capabilities\n",
    "    - There is a closer relationship between operators and machine instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Operators\n",
    "\n",
    "- Because each machine instruction can be executed in a fixed number of cycles, we may assume each operation requires a *fixed number of cycles*\n",
    "- The time required for any operator is $\\Theta(1)$ including:\n",
    "    - Retrieving/storing variables from memory\n",
    "    - Variable assignment, `=`\n",
    "    - Integer operations, `+ - * / % ++ --`\n",
    "    - Logical operations, `&& || !`\n",
    "    - Bitwise operations, `& | ^ ~`\n",
    "    - Relational operations, `== != < <= => >`\n",
    "    - Memory allocation and deallocation, `new delete`\n",
    "- Memory allocation and deallocation are the slowest by a significant factor\n",
    "    - Note that after memory is allocated, the constructor is run\n",
    "        - The constructor may not run in $\\Theta(1)$ time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Blocks of Operations\n",
    "\n",
    "- If each operation runs in $\\Theta(1)$ time, then any fixed number of operations also run in $\\Theta(1)$ time, for example:\n",
    "```c\n",
    "// Swap variables a and b\n",
    "int tmp = a;\n",
    "a = b;\n",
    "b = tmp;\n",
    "```\n",
    "\n",
    "- Seldom will you find large blocks of operations without any additional control statements:\n",
    "    - Remove node from the DL list\n",
    "```cpp\n",
    "p->prev->next = p->next;\n",
    "p->next->prev = p->prev;\n",
    "delete p;\n",
    "```\n",
    "    - Run time: $\\Theta(1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Blocks in Sequence\n",
    "\n",
    "- Suppose you have now analyzed a number of blocks of code run in sequence\n",
    "\n",
    "```cpp\n",
    "template <typename T>\n",
    "void update_capacity( int delta ) {\n",
    "\tT *array_old = array;                      //-------\n",
    "\tint capacity_old = array_capacity;         //  Θ(1)\n",
    "    array_capacity += delta;                   //  \n",
    "\tarray = new T[array_capacity];             //-------\n",
    "\tfor ( int i = 0; i < capacity_old; ++i ) { //-------        \n",
    "\t\tarray[i] = array_old[i];               //  Θ(n)\n",
    "\t}                                          //-------\n",
    "\tdelete[] array_old;                        // Θ(1) or Ω(𝑛)\n",
    "}\n",
    "```\n",
    "- To calculate the total run time, add the entries: $\\Theta(1 + n + 1) = \\Theta(n)$\n",
    "    - When considering a sum, *take the dominant term*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Control Statements\n",
    "\n",
    "- These are statements which potentially alter the execution of instructions\n",
    "    - Conditional statements `if, switch`\n",
    "    - Condition-controlled loops `for, while, do-while`\n",
    "    - Collection-controlled loops `for ( auto i : array ) {...}`\n",
    "    \n",
    "- Given any collection of nested control statements, it is always necessary to **work inside out**\n",
    "    - Determine the run times of the inner-most statements and work your way out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Statement\n",
    "\n",
    "- Given\n",
    "```cpp\n",
    "if ( condition ) {\n",
    "    // true body\n",
    "} else {\n",
    "    // false body\n",
    "}\n",
    "```\n",
    "- The run time of a conditional statement is:\n",
    "    - the run time of the *condition* (the test), **plus**\n",
    "    - the run time of the *body which is run*\n",
    "\n",
    "- In most cases, the run time of the condition is $\\Theta(1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "Sometimes, it's less obvious\n",
    "```cpp\n",
    "int find_max( int *array, int n ) {\n",
    "    int max = array[0];\n",
    "    for ( int i = 1; i < n; ++i ) {\n",
    "        if ( array[i] > max ) {     //---------            \n",
    "            max = array[i];         //  Θ(???)\n",
    "        }                           //---------\n",
    "    }\n",
    "    return max;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we had information about the distribution of the entries of the array, we may be able to determine it\n",
    "    - if the list is sorted (ascending) it will always be run\n",
    "    - if the list is sorted (descending) it will be run once\n",
    "    - if the list is uniformly randomly distributed, then???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Condition-controlled Loops\n",
    "\n",
    "- The C++ for loop is a condition controlled statement:\n",
    "```cpp    \n",
    "for ( int i = 0; i < n; ++i ) {\n",
    "    // ...\n",
    "}\n",
    "```    \n",
    "is identical to\n",
    "```cpp\n",
    "int i = 0;        // initialization\n",
    "while ( i < n ) { // condition\n",
    "    // ...\n",
    "    ++i;            // increment\n",
    "}\n",
    "```\n",
    "- Assuming there are no break or return statements in the loop, the run time is $\\Omega(n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The initialization, condition, and increment usually are single statements running in $\\Theta(1)$\n",
    "```cpp    \n",
    "for ( int i = 0; i < n; ++i ) {\n",
    "    // code that runs in Θ(f(m))\n",
    "}\n",
    "```\n",
    "\n",
    "- If the body **does not depend** on the variable (in this example, `i`), then the run time of $\\Theta(n f(m))$\n",
    "- If the body is $O(f(m))$, then the run time of the loop is $O(n f(m))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- For example,\n",
    "```cpp\n",
    "int sum = 0; \n",
    "for ( int i = 0; i < n; ++i ) {\n",
    "    sum += 1; // Θ(1)\n",
    "}\n",
    "```\n",
    "- This code has run time $\\Theta(n \\cdot 1) = \\Theta(n)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- For example,\n",
    "```cpp\n",
    "int sum = 0; \n",
    "for ( int i = 0; i < n; ++i ) { \n",
    "    for ( int j = 0; j < n; ++j ) {\n",
    "        sum += 1; // Θ(1)\n",
    "    }\n",
    "}\n",
    "```\n",
    "- The previous example showed that the inner loop is $\\Theta(n)$, thus the outer loop is $\\Theta(n \\cdot n) = \\Theta(n^2)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Repetition Statements\n",
    "\n",
    "- Suppose with each loop, we use a linear search an array of size $m$:\n",
    "```cpp\n",
    "int sum = 0; \n",
    "for ( int i = 0; i < n; ++i ) {\n",
    "    // search through an array of size m, O(m)\n",
    "}\n",
    "```\n",
    "- The inner loop is $O(m)$ and thus the outer loop is $O(n \\cdot m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- If the body **does depends** on the variable (in this example, `i`), then the run time of \n",
    "```cpp\n",
    "for ( int i = 0; i < n; ++i ) {\n",
    " // code which is Θ(f(i,n))\n",
    "}\n",
    "```\n",
    "is $\\Theta\\left(1 + \\sum_{i=0}^{n-1}(1+f(i,n))\\right)$\n",
    "- If the body is $O(f(i, n))$, the result is\n",
    "$$O\\left(1 + \\sum_{i=0}^{n-1}(1+f(i,n))\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- For example,\n",
    "```cpp\n",
    "int sum = 0; \n",
    "for ( int i = 0; i < n; ++i ) { \n",
    "    for ( int j = 0; j < i; ++j ) {\n",
    "        sum += i + j;\n",
    "    }\n",
    "}\n",
    "```\n",
    "- The inner loop is $\\Theta(1 + i(1 + 1) ) = \\Theta(i)$ hence the outer is\n",
    "$$\\Theta\\left(1 + \\sum_{i=0}^{n-1}(1+i)\\right) = \\Theta\\left(1 + n + \\sum_{i=0}^{n-1}i\\right) =$$\n",
    "$$\\Theta\\left(1 + n + \\frac{n(n-1)}{2}\\right) = \\Theta(n^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Serial Statements\n",
    "\n",
    "- Suppose we run one block of code followed by another block of code\n",
    "    - Such code is said to be run **serially**\n",
    "\n",
    "- If the first block of code is $O(f(n))$ and the second is $O(g(n))$, then the run time of two blocks of code is\n",
    "$$O( f(n) + g(n) )$$\n",
    "which usually (for algorithms not including function calls) simplifies to one or the other\n",
    "\n",
    "- What is the proper means of describing the run time of these two algorithms?\n",
    "    - if the leading term is big-$\\Theta$, then the result must be big-$\\Theta$, otherwise\n",
    "    - if the leading term is big-$O$, we can say the result is big-$O$  \n",
    "\n",
    "- For example,\n",
    "$$O(n) + O(n^2) + O(n^4) = O(n + n^2 + n^4) = O(n^4)$$\n",
    "$$O(n) + \\Theta(n^2) = \\Theta(n^2)$$\n",
    "$$O(n^2) + \\Theta(n) = O(n^2)$$\n",
    "$$O(n^2) + \\Theta(n^2) = \\Theta(n^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Functions\n",
    "\n",
    "- A function (or subroutine) is code which is composed of repeated operations\n",
    "- Because a function can be called from anywhere, we must:\n",
    "    - prepare the appropriate environment\n",
    "    - deal with arguments (parameters)\n",
    "    - jump to the subroutine\n",
    "    - execute the subroutine\n",
    "    - deal with the return value\n",
    "    - clean up\n",
    "\n",
    "- On modern processors most of these steps in one instruction\n",
    "    - Thus, we will assume that the overhead required to make a function call and to return is $\\Theta(1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Because any function requires the overhead of a function call and return, we will always assume that\n",
    "$$T_f = \\Omega(1)$$\n",
    "    - That is, it is impossible for any function call to have a zero run time\n",
    "    \n",
    "- Thus, given a function $f(n)$ (the run time of which depends on n) we will associate the run time of $f(n)$ by some function $T_f(n)$\n",
    "    - We may write this to $T(n)$\n",
    "\n",
    "- Because the run time of any function is at least $O(1)$, we will include the time required to both call and return from the function in the run time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recursive Functions\n",
    "\n",
    "- A function is relatively simple if it simply performs operations and calls other functions\n",
    "- Most interesting functions designed to solve problems usually end up calling themselves\n",
    "    - Such a function is said to be **recursive**\n",
    "    \n",
    "```cpp\n",
    "int factorial( int n ) {\n",
    "    if ( n <= 1 ) {\n",
    "        return 1;                       // Θ(1)\n",
    "    } else {\n",
    "        return n * factorial( n - 1 );  // 𝑇(n-1) + Θ(1)\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Thus, we may analyze the run time of this function as follows:\n",
    "$$T(n) = \\begin{cases}\n",
    "\\Theta(1) & n \\leq 1 \\\\\n",
    "T(n-1) + \\Theta(1) & n > 1 \\\\\n",
    "\\end{cases}$$    \n",
    "- We don't have to worry about the time of the conditional ($\\Theta(1)$) nor is there a probability involved with the conditional statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The analysis of the run time of this function yields a recurrence relation\n",
    "$$T(n) = T(n-1) + \\Theta(1), \\; \\; \\; T(1) = \\Theta(1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Replace each Landau symbol with a representative function\n",
    "$$T(n) = T(n-1) + 1, \\; \\; \\; T(1) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Try to solve equations by examining the first few steps:\n",
    "$$T(n) = T(n - 1) + 1$$\n",
    "$$ = T(n - 2) + 1 + 1 = T(n - 2) + 2$$\n",
    "$$ = T(n - 3) + 3$$\n",
    "\n",
    "- From this, we see a pattern:\n",
    "$$T(n) = T(n – k) + k$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $k = n - 1$ then\n",
    "$$T(n) = T(n – (n – 1)) + n – 1$$\n",
    "$$= T(1) + n – 1 = 1 + n – 1 = n$$\n",
    "- Thus, $T(n) = \\Theta(n)$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
